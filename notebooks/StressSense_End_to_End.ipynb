{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1fb5a1",
   "metadata": {},
   "source": [
    "# StressSense — Early Stress Risk Screener\n",
    "_End-to-End ML Notebook (EDA → Preprocessing → 2+ Models → Evaluation → Explainability → Demo)_\n",
    "\n",
    "**Author:** Your Name  \n",
    "**Cohort:** Week 3 — Classification with 2+ algorithms  \n",
    "**Note:** This tool is educational and not a medical diagnosis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6316c93d",
   "metadata": {},
   "source": [
    "## 1) Project Overview\n",
    "**Goal:** Predict an individual's **stress level** (Low/Moderate/High) using lifestyle, study/work, and wellbeing indicators.\n",
    "\n",
    "**You will deliver:**\n",
    "- Clean EDA & preprocessing\n",
    "- Train at least **two classifiers** (Logistic Regression + RandomForest; optional GradientBoosting)\n",
    "- Model evaluation & comparison table\n",
    "- Explainability (global feature importance; optional SHAP)\n",
    "- Save artifacts & run a tiny **Gradio** demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dca783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Setup\n",
    "!python --version\n",
    "import sys, os, json, warnings, math\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = '../data/sample_stress_data.csv'  # <-- Replace with your dataset path if needed\n",
    "MODEL_DIR = '../models'\n",
    "ARTIFACT_DIR = '../artifacts'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "\n",
    "print('Using data at:', DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b020b",
   "metadata": {},
   "source": [
    "## 3) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000ea8bf",
   "metadata": {},
   "source": [
    "## 4) Quick Data Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe(include='all').T)\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Drop obvious duplicates, if any\n",
    "before = df.shape[0]\n",
    "df = df.drop_duplicates()\n",
    "after = df.shape[0]\n",
    "print(f\"Dropped duplicates: {before - after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9120291",
   "metadata": {},
   "source": [
    "## 5) Define Target and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try common target names; fallback to last column if not found\n",
    "possible_targets = ['stress_level', 'Stress Level', 'stress', 'label', 'target']\n",
    "target_col = None\n",
    "for c in possible_targets:\n",
    "    if c in df.columns:\n",
    "        target_col = c\n",
    "        break\n",
    "if target_col is None:\n",
    "    target_col = df.columns[-1]\n",
    "print('Target column assumed as:', target_col)\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype('category')\n",
    "\n",
    "print('Classes:', list(y.cat.categories))\n",
    "num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=['int64','float64']).columns.tolist()\n",
    "print('Numeric:', num_cols)\n",
    "print('Categorical:', cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9903322",
   "metadata": {},
   "source": [
    "## 6) Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d641cc",
   "metadata": {},
   "source": [
    "## 7) Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3419c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ccf929",
   "metadata": {},
   "source": [
    "## 8) Train Multiple Models (2+ classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogReg': LogisticRegression(max_iter=1000, multi_class='auto', n_jobs=None if 'n_jobs' in LogisticRegression().get_params() else None),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "fitted = {}\n",
    "metrics_table = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline(steps=[('preprocess', preprocess), ('clf', clf)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_prob = None\n",
    "    if hasattr(pipe.named_steps['clf'], 'predict_proba'):\n",
    "        y_prob = pipe.predict_proba(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    # Macro-average for multi-class\n",
    "    prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # ROC-AUC (macro) if proba available and >2 classes use OvR\n",
    "    auc = np.nan\n",
    "    try:\n",
    "        if y_prob is not None:\n",
    "            # binarize labels for multiclass\n",
    "            from sklearn.preprocessing import label_binarize\n",
    "            classes = list(y.cat.categories)\n",
    "            y_bin = label_binarize(y_test, classes=classes)\n",
    "            auc = roc_auc_score(y_bin, y_prob, average='macro', multi_class='ovr')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    metrics_table.append([name, acc, prec, rec, f1, auc])\n",
    "    fitted[name] = pipe\n",
    "    print(f\"\"\"\\n=== {name} ===\n",
    "Accuracy: {acc:.3f} | Precision(macro): {prec:.3f} | Recall(macro): {rec:.3f} | F1(macro): {f1:.3f} | ROC-AUC(macro): {auc if not math.isnan(auc) else 'NA'}\n",
    "\"\"\")\n",
    "    \n",
    "# Summary table\n",
    "mt = pd.DataFrame(metrics_table, columns=['Model','Accuracy','Precision(macro)','Recall(macro)','F1(macro)','ROC-AUC(macro)']).sort_values('F1(macro)', ascending=False)\n",
    "mt.reset_index(drop=True, inplace=True)\n",
    "mt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4bebf",
   "metadata": {},
   "source": [
    "## 9) Pick Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff43eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = mt.iloc[0]\n",
    "best_model_name = best_row['Model']\n",
    "best_model = fitted[best_model_name]\n",
    "print('Best model:', best_model_name)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa38f04",
   "metadata": {},
   "source": [
    "## 10) Confusion Matrix (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f30d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_best, labels=list(y.cat.categories))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(y.cat.categories))\n",
    "fig, ax = plt.subplots(figsize=(4.5,4))\n",
    "disp.plot(ax=ax, xticks_rotation=45)\n",
    "plt.title(f'Confusion Matrix — {best_model_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605566b6",
   "metadata": {},
   "source": [
    "## 11) Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063aa5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try permutation importance (model-agnostic)\n",
    "try:\n",
    "    # To compute permutation importance, we need a fitted pipeline.\n",
    "    # We'll compute on a sample to be fast.\n",
    "    result = permutation_importance(best_model, X_test, y_test, n_repeats=5, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    importances = result.importances_mean\n",
    "    # Get feature names from ColumnTransformer\n",
    "    ohe = best_model.named_steps['preprocess'].named_transformers_['cat'].named_steps['ohe'] if len(cat_cols) > 0 else None\n",
    "    num_names = num_cols\n",
    "    cat_names = []\n",
    "    if ohe is not None:\n",
    "        cat_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "    feature_names = num_names + cat_names\n",
    "    \n",
    "    fi = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False).head(15)\n",
    "    fi.reset_index(drop=True, inplace=True)\n",
    "    display(fi)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.barh(fi['feature'][::-1], fi['importance'][::-1])\n",
    "    ax.set_xlabel('Permutation Importance')\n",
    "    ax.set_title('Top Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Permutation importance failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef2afb4",
   "metadata": {},
   "source": [
    "## 12) Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023779d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model pipeline\n",
    "model_path = f\"{MODEL_DIR}/stresssense_best_pipeline.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "print('Saved:', model_path)\n",
    "\n",
    "# Save feature types & UI metadata for the demo app\n",
    "ui_meta = {\n",
    "    'numeric_cols': num_cols,\n",
    "    'categorical_cols': {},\n",
    "    'ranges': {}\n",
    "}\n",
    "for c in num_cols:\n",
    "    lo = float(np.nanpercentile(df[c], 5)) if pd.api.types.is_numeric_dtype(df[c]) else 0.0\n",
    "    hi = float(np.nanpercentile(df[c], 95)) if pd.api.types.is_numeric_dtype(df[c]) else 1.0\n",
    "    ui_meta['ranges'][c] = [lo, hi]\n",
    "for c in cat_cols:\n",
    "    opts = sorted([str(v) for v in pd.Series(df[c].dropna().unique()).astype(str)])\n",
    "    ui_meta['categorical_cols'][c] = opts\n",
    "\n",
    "meta_path = f\"{ARTIFACT_DIR}/feature_types.json\"\n",
    "with open(meta_path, 'w') as f:\n",
    "    json.dump(ui_meta, f, indent=2)\n",
    "print('Saved:', meta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f66ee",
   "metadata": {},
   "source": [
    "## 13) Single Prediction Helper + Natural Language Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(input_dict, model=best_model):\n",
    "    \"\"\"input_dict: mapping of original column names to values.\"\"\"\n",
    "    X_one = pd.DataFrame([input_dict])\n",
    "    pred = model.predict(X_one)[0]\n",
    "    prob = None\n",
    "    if hasattr(model.named_steps['clf'], 'predict_proba'):\n",
    "        probs = model.predict_proba(X_one)[0]\n",
    "        classes = model.classes_\n",
    "        prob = dict(zip(classes, probs))\n",
    "    return pred, prob\n",
    "\n",
    "def summarize_explanation(prob_dict):\n",
    "    if prob_dict is None:\n",
    "        return 'Model does not provide class probabilities.'\n",
    "    top = sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)[0]\n",
    "    msg = f\"Predicted **{top[0]}** with confidence {top[1]*100:.1f}%. Consider improving sleep hygiene, balancing work/screen time, and regular physical activity.\"\n",
    "    return msg\n",
    "\n",
    "# Example with random row from test set\n",
    "example = X_test.iloc[0].to_dict()\n",
    "pred, prob = predict_one(example, best_model)\n",
    "print('Example input:', example)\n",
    "print('Prediction:', pred)\n",
    "print('Probs:', prob)\n",
    "print(summarize_explanation(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533fd414",
   "metadata": {},
   "source": [
    "## 14) (Optional) SHAP Explainability (Local Only)\n",
    "Uncomment the cell below and install `shap` locally to view per-instance explanations. In some hosted notebooks, SHAP may be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72259ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# pip install shap -q\n",
    "\n",
    "# import shap\n",
    "# explainer = None\n",
    "# try:\n",
    "#     # TreeExplainer works well for tree models like RandomForest/GB\n",
    "#     if isinstance(best_model.named_steps['clf'], (RandomForestClassifier, GradientBoostingClassifier)):\n",
    "#         # Create a reduced background to speed up\n",
    "#         X_trans = best_model.named_steps['preprocess'].transform(X_train.sample(min(200, len(X_train)), random_state=RANDOM_STATE))\n",
    "#         explainer = shap.TreeExplainer(best_model.named_steps['clf'])\n",
    "#         shap_values = explainer.shap_values(X_trans)\n",
    "#         shap.summary_plot(shap_values, X_trans, show=False)\n",
    "#         plt.title('SHAP Summary (subset)')\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print('SHAP demo: best model is not a tree-based model; skipping.')\n",
    "# except Exception as e:\n",
    "#     print('SHAP failed/slow:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559abb33",
   "metadata": {},
   "source": [
    "## 15) Next Steps\n",
    "- Export PDF: *File → Print → Save as PDF*.\n",
    "- Commit notebook + artifacts to GitHub.\n",
    "- Launch the Gradio app (below) locally to demo the model.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
